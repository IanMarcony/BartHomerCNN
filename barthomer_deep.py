# -*- coding: utf-8 -*-
"""BartHomer-Deep.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nxww2Bqt8GyOYkUBqoNyOe0hcYmi7s4k
"""

#Importar dados essenciais
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder

#Reading Dataset
from google.colab import drive
drive.mount('/content/drive/')


dataset = pd.read_csv('/content/drive/My Drive/CursoIA/ClassBartHomer/personagens.csv')
dataset

#Splitting dataset
previsores = dataset.iloc[:, 0:6].values
print(previsores)
classes = dataset.iloc[:,6].values
print(classes)

labelEncoder = LabelEncoder()
classes =  labelEncoder.fit_transform(classes)
print(classes)

from sklearn.model_selection import train_test_split
previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classes, test_size=0.25)

previsores_treinamento

classe_treinamento

classificador = Sequential()
classificador.add(Dense(units =  6,
                        activation = 'relu',
                        input_dim = 6))
classificador.add(Dense(units =  4,
                        activation = 'relu'))
classificador.add(Dense(units =  1,
                        activation = 'sigmoid',
                        ))
classificador.compile(optimizer = 'adam',
                      loss = 'binary_crossentropy',
                      metrics = ['accuracy'])

classificador.fit(previsores_treinamento,
                  classe_treinamento,
                  validation_data = (previsores_teste, classe_teste),
                  batch_size = 10,
                  epochs = 500)