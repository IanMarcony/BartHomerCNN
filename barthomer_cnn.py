# -*- coding: utf-8 -*-
"""BartHomer-CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Enkex1K5qyWDYz42y3fPPlWhnssIJ3MF
"""

#Importar dados essenciais
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import BatchNormalization

#Reading image files
from google.colab import drive
drive.mount('/content/drive/')

#Image generator
gerador_treinamento  = ImageDataGenerator(rescale = 1./255,
                                          rotation_range = 7,
                                          horizontal_flip = True,
                                          shear_range = 0.2,
                                          height_shift_range = 0.07,
                                          zoom_range = 0.2)
gerador_teste = ImageDataGenerator(rescale = 1./255)

base_treinamento = gerador_treinamento.flow_from_directory('/content/drive/My Drive/CursoIA/ClassBartHomer/dataset_personagens/training_set',
                                                           target_size = (64,64),
                                                           batch_size = 10,
                                                           class_mode = 'binary')

base_test = gerador_teste.flow_from_directory('/content/drive/My Drive/CursoIA/ClassBartHomer/dataset_personagens/test_set',
                                                           target_size = (64,64),
                                                           batch_size = 10,
                                                           class_mode = 'binary')

classificador = Sequential()
classificador.add(Conv2D(32, (3,3), input_shape=(64,64,3), activation= 'relu'))
classificador.add(BatchNormalization())
classificador.add(MaxPooling2D(pool_size = (2,2)))

classificador.add(Conv2D(32, (3,3), activation= 'relu'))
classificador.add(BatchNormalization())
classificador.add(MaxPooling2D(pool_size = (2,2)))

classificador.add(Flatten())

classificador.add(Dense(units = 128, activation = 'relu'))
classificador.add(Dropout(0.2))
classificador.add(Dense(units = 128, activation = 'relu'))
classificador.add(Dropout(0.2))
classificador.add(Dense(units = 1, activation = 'sigmoid'))

classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy',
                      metrics = ['accuracy'])

len(base_treinamento.filepaths)/base_treinamento.batch_size

classificador.fit(base_treinamento, steps_per_epoch = len(base_treinamento),
                  epochs = 30, validation_data = base_test,
                  validation_steps = len(base_test))

#Predicting
from keras.preprocessing import image
from keras.utils import img_to_array
print(base_treinamento.class_indices)
resultados = []
for path in base_test.filepaths:
  imagem_teste = image.load_img(path, target_size = (64,64))
  imagem_teste = img_to_array(imagem_teste)
  imagem_teste /= 255
  imagem_teste = np.expand_dims(imagem_teste, axis =0)

  previsao = classificador.predict(imagem_teste)
  classe_real = path.split('/')
  classe_real = classe_real[len(classe_real)-2]
  classe_prevista = 'bart' if previsao<0.55 else 'homer'
  percent = previsao[0]*100

  print(f'Classe real: {classe_real} = Classe prevista: { classe_prevista} Percent = {percent}%')

batch_images = next(base_treinamento)[0]
batch_size = 4
import matplotlib.pyplot as plt
# Create subplots
fig, ax = plt.subplots(nrows=1, ncols=batch_size, figsize=(15, 15))
# Iterate through the batch of images and display them
for i in range(batch_size):
  image = batch_images[i]
  ax[i].imshow(image, cmap='gray', vmin=0, vmax=65535) # Display using a grayscale colormap and 16-bit range
  ax[i].axis('off')
  plt.show()